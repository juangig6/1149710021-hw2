#!/usr/bin/env python
# -*- coding: utf-8 -*-
"""
Part B: ç¾ä»£ AI æ–¹æ³• (30 åˆ†)
ä½¿ç”¨ OpenAI gpt-4o API å®Œæˆç›¸åŒä»»å‹™
åŒ…å« B-1, B-2, B-3 ä¸‰å€‹ä»»å‹™
"""
import sys
import os
import json
from openai import OpenAI

# è¼‰å…¥ç’°å¢ƒè®Šæ•¸
try:
    from dotenv import load_dotenv
    load_dotenv()  # å¾ž .env æª”æ¡ˆè¼‰å…¥ç’°å¢ƒè®Šæ•¸
    print("âœ“ å·²è¼‰å…¥ .env æª”æ¡ˆ")
except ImportError:
    print("â„¹ python-dotenv æœªå®‰è£ï¼Œä½¿ç”¨ç³»çµ±ç’°å¢ƒè®Šæ•¸")
except Exception as e:
    print(f"â„¹ è¼‰å…¥ .env æª”æ¡ˆæ™‚ç™¼ç”ŸéŒ¯èª¤: {e}")

# ============================================================
# B-1: èªžæ„ç›¸ä¼¼åº¦è¨ˆç®— (10 åˆ†)
# ============================================================
def run_b1():
    """B-1: èªžæ„ç›¸ä¼¼åº¦è¨ˆç®—"""
    print("\nB-1: èªžæ„ç›¸ä¼¼åº¦è¨ˆç®— (10 åˆ†)")
    print("="*60)
    print("ä½¿ç”¨ gpt-4o åˆ¤æ–·èªžæ„ç›¸ä¼¼åº¦\n")
    
    def ai_similarity(text1, text2, api_key):
        """
        ä½¿ç”¨ gpt-4o åˆ¤æ–·èªžæ„ç›¸ä¼¼åº¦
        
        è¦æ±‚:
        1. è¨­è¨ˆé©ç•¶çš„ prompt
        2. è¿”å›ž 0-100 çš„ç›¸ä¼¼åº¦åˆ†æ•¸
        3. è™•ç† API éŒ¯èª¤
        """
        try:
            client = OpenAI(api_key=api_key)
            
            prompt = f"""
è«‹è©•ä¼°ä»¥ä¸‹å…©æ®µæ–‡å­—çš„èªžæ„ç›¸ä¼¼åº¦ã€‚
è€ƒæ…®å› ç´ :
1. ä¸»é¡Œç›¸é—œæ€§
2. èªžæ„é‡ç–Šç¨‹åº¦
3. è¡¨é”çš„è§€é»žæ˜¯å¦ä¸€è‡´

æ–‡å­—1: {text1}
æ–‡å­—2: {text2}

è«‹åªå›žç­”ä¸€å€‹0-100çš„æ•¸å­—ï¼Œä»£è¡¨ç›¸ä¼¼åº¦ç™¾åˆ†æ¯”ã€‚
æ•¸å­—è¶Šé«˜è¡¨ç¤ºè¶Šç›¸ä¼¼ï¼Œä¸éœ€è¦å…¶ä»–èªªæ˜Žã€‚
"""
            
            response = client.chat.completions.create(
                model="gpt-4o",
                messages=[
                    {"role": "system", "content": "ä½ æ˜¯ä¸€å€‹å°ˆæ¥­çš„æ–‡æœ¬ç›¸ä¼¼åº¦åˆ†æžåŠ©æ‰‹ï¼Œåªéœ€å›žç­”æ•¸å­—ã€‚"},
                    {"role": "user", "content": prompt}
                ],
                temperature=0.3,
                max_tokens=10
            )
            
            # æå–ç›¸ä¼¼åº¦åˆ†æ•¸
            result = response.choices[0].message.content.strip()
            
            # å˜—è©¦å¾žå›žæ‡‰ä¸­æå–æ•¸å­—
            import re
            numbers = re.findall(r'\d+', result)
            if numbers:
                similarity_score = int(numbers[0])
                # ç¢ºä¿åœ¨ 0-100 ç¯„åœå…§
                similarity_score = max(0, min(100, similarity_score))
            else:
                similarity_score = 50  # é»˜èªå€¼
            
            return {
                'similarity': similarity_score,
                'raw_response': result
            }
            
        except Exception as e:
            print(f"âš  API éŒ¯èª¤: {e}")
            return {
                'similarity': -1,
                'error': str(e)
            }
    
    # æ¸¬è©¦æ•¸æ“š
    test_pairs = [
        ("äººå·¥æ™ºæ…§æ­£åœ¨æ”¹è®Šä¸–ç•Œ", "AIæŠ€è¡“revolutionizingæˆ‘å€‘çš„ç”Ÿæ´»"),
        ("ä»Šå¤©å¤©æ°£å¾ˆå¥½", "è‚¡å¸‚ä»Šå¤©ä¸Šæ¼²äº†"),
        ("æˆ‘å–œæ­¡åƒæŠ«è–©", "æŠ«è–©æ˜¯æˆ‘æœ€æ„›çš„é£Ÿç‰©"),
        ("æ©Ÿå™¨å­¸ç¿’æ˜¯AIçš„ä¸€éƒ¨åˆ†", "æ·±åº¦å­¸ç¿’å±¬æ–¼æ©Ÿå™¨å­¸ç¿’é ˜åŸŸ")
    ]
    
    print("æ¸¬è©¦æ–‡æœ¬å°:")
    print("-"*60)
    for i, (text1, text2) in enumerate(test_pairs, 1):
        print(f"\n{i}. æ–‡å­—1: {text1}")
        print(f"   æ–‡å­—2: {text2}")
    
    # æª¢æŸ¥ API Key
    api_key = os.getenv('OPENAI_API_KEY')
    if not api_key:
        print("\n" + "="*60)
        print("âš  è­¦å‘Š: æœªè¨­ç½® OPENAI_API_KEY ç’°å¢ƒè®Šæ•¸")
        print("="*60)
        print("\nè«‹è¨­ç½®ç’°å¢ƒè®Šæ•¸:")
        print("  Windows: set OPENAI_API_KEY=your-api-key")
        print("  Linux/Mac: export OPENAI_API_KEY=your-api-key")
        print("\næˆ–åœ¨ç¨‹å¼ä¸­ç›´æŽ¥è¨­ç½®:")
        print("  api_key = 'your-api-key'")
        print("\nä½¿ç”¨æ¨¡æ“¬æ•¸æ“šé€²è¡Œæ¼”ç¤º...")
        
        # ä½¿ç”¨æ¨¡æ“¬æ•¸æ“š
        print("\n" + "="*60)
        print("ç›¸ä¼¼åº¦è¨ˆç®—çµæžœ (æ¨¡æ“¬)")
        print("="*60)
        
        mock_results = [85, 15, 92, 88]
        for i, ((text1, text2), score) in enumerate(zip(test_pairs, mock_results), 1):
            print(f"\n{i}. æ–‡å­—1: {text1}")
            print(f"   æ–‡å­—2: {text2}")
            print(f"   ç›¸ä¼¼åº¦: {score}%")
    else:
        # å¯¦éš›èª¿ç”¨ API
        print("\n" + "="*60)
        print("ç›¸ä¼¼åº¦è¨ˆç®—çµæžœ")
        print("="*60)
        
        results = []
        for i, (text1, text2) in enumerate(test_pairs, 1):
            print(f"\næ­£åœ¨è¨ˆç®—ç¬¬ {i} å°ç›¸ä¼¼åº¦...")
            result = ai_similarity(text1, text2, api_key)
            results.append(result)
            
            print(f"{i}. æ–‡å­—1: {text1}")
            print(f"   æ–‡å­—2: {text2}")
            if 'error' in result:
                print(f"   éŒ¯èª¤: {result['error']}")
            else:
                print(f"   ç›¸ä¼¼åº¦: {result['similarity']}%")
                print(f"   åŽŸå§‹å›žæ‡‰: {result['raw_response']}")
        
        # å„²å­˜çµæžœ
        os.makedirs('results', exist_ok=True)
        with open('results/b1_similarity_results.json', 'w', encoding='utf-8') as f:
            json.dump({
                'test_pairs': [{'text1': t1, 'text2': t2} for t1, t2 in test_pairs],
                'results': results
            }, f, ensure_ascii=False, indent=2)
        
        print("\nâœ“ çµæžœå·²å„²å­˜è‡³: results/b1_similarity_results.json")
    
    print("\n" + "="*60)
    print("âœ“ B-1 å®Œæˆï¼")
    print("="*60)


# ============================================================
# B-2: AI æ–‡æœ¬åˆ†é¡ž (10 åˆ†)
# ============================================================
def run_b2():
    """B-2: AI æ–‡æœ¬åˆ†é¡ž"""
    print("\n\nB-2: AI æ–‡æœ¬åˆ†é¡ž (10 åˆ†)")
    print("="*60)
    print("ä½¿ç”¨ gpt-4o é€²è¡Œå¤šç¶­åº¦åˆ†é¡ž\n")
    
    def ai_classify(text, api_key):
        """
        ä½¿ç”¨ gpt-4o é€²è¡Œå¤šç¶­åº¦åˆ†é¡ž
        
        è¿”å›žæ ¼å¼:
        {
            "sentiment": "æ­£é¢/è² é¢/ä¸­æ€§",
            "topic": "ä¸»é¡Œé¡žåˆ¥",
            "confidence": 0.95
        }
        """
        try:
            client = OpenAI(api_key=api_key)
            
            prompt = f"""
è«‹åˆ†æžä»¥ä¸‹æ–‡æœ¬çš„æƒ…æ„Ÿå’Œä¸»é¡Œ:

æ–‡æœ¬: {text}

è«‹ä»¥JSONæ ¼å¼å›žç­”ï¼ŒåŒ…å«ä»¥ä¸‹æ¬„ä½:
1. sentiment: æƒ…æ„Ÿåˆ†é¡ž (æ­£é¢/è² é¢/ä¸­æ€§)
2. topic: ä¸»é¡Œåˆ†é¡ž (ç§‘æŠ€/é‹å‹•/ç¾Žé£Ÿ/æ—…éŠ/å…¶ä»–)
3. confidence: ä¿¡å¿ƒåº¦ (0.0-1.0)

åªéœ€å›žç­”JSONï¼Œä¸è¦å…¶ä»–èªªæ˜Žã€‚
ç¯„ä¾‹æ ¼å¼:
{{"sentiment": "æ­£é¢", "topic": "ç¾Žé£Ÿ", "confidence": 0.95}}
"""
            
            response = client.chat.completions.create(
                model="gpt-4o",
                messages=[
                    {"role": "system", "content": "ä½ æ˜¯ä¸€å€‹å°ˆæ¥­çš„æ–‡æœ¬åˆ†é¡žåŠ©æ‰‹ï¼Œå›žç­”å¿…é ˆæ˜¯æœ‰æ•ˆçš„JSONæ ¼å¼ã€‚"},
                    {"role": "user", "content": prompt}
                ],
                temperature=0.3,
                max_tokens=100
            )
            
            result = response.choices[0].message.content.strip()
            
            # æ¸…ç†å¯èƒ½çš„ markdown ä»£ç¢¼å¡Šæ¨™è¨˜
            result = result.replace('```json', '').replace('```', '').strip()
            
            # è§£æž JSON
            classification = json.loads(result)
            
            return classification
            
        except json.JSONDecodeError as e:
            print(f"âš  JSON è§£æžéŒ¯èª¤: {e}")
            print(f"åŽŸå§‹å›žæ‡‰: {result}")
            return {
                'sentiment': 'æœªçŸ¥',
                'topic': 'å…¶ä»–',
                'confidence': 0.0,
                'error': 'JSONè§£æžå¤±æ•—'
            }
        except Exception as e:
            print(f"âš  API éŒ¯èª¤: {e}")
            return {
                'sentiment': 'æœªçŸ¥',
                'topic': 'å…¶ä»–',
                'confidence': 0.0,
                'error': str(e)
            }
    
    # æ¸¬è©¦æ•¸æ“š
    test_texts = [
        "é€™å®¶é¤å»³çš„ç‰›è‚‰éºµçœŸçš„å¤ªå¥½åƒäº†ï¼Œæ¹¯é ­æ¿ƒéƒï¼Œéºµæ¢Qå½ˆï¼Œä¸‹æ¬¡ä¸€å®šå†ä¾†ï¼",
        "æœ€æ–°çš„AIæŠ€è¡“çªç ´è®“äººé©šè‰·ï¼Œæ·±åº¦å­¸ç¿’æ¨¡åž‹çš„è¡¨ç¾è¶Šä¾†è¶Šå¥½",
        "é€™éƒ¨é›»å½±åŠ‡æƒ…ç©ºæ´žï¼Œæ¼”æŠ€ç³Ÿç³•ï¼Œå®Œå…¨æ˜¯æµªè²»æ™‚é–“",
        "æ¯å¤©æ…¢è·‘5å…¬é‡Œï¼Œé…åˆé©ç•¶çš„é‡è¨“ï¼Œé«”èƒ½é€²æ­¥å¾ˆå¤š"
    ]
    
    print("æ¸¬è©¦æ–‡æœ¬:")
    print("-"*60)
    for i, text in enumerate(test_texts, 1):
        print(f"{i}. {text}")
    
    # æª¢æŸ¥ API Key
    api_key = os.getenv('OPENAI_API_KEY')
    if not api_key:
        print("\n" + "="*60)
        print("âš  è­¦å‘Š: æœªè¨­ç½® OPENAI_API_KEY ç’°å¢ƒè®Šæ•¸")
        print("="*60)
        print("\nä½¿ç”¨æ¨¡æ“¬æ•¸æ“šé€²è¡Œæ¼”ç¤º...")
        
        # ä½¿ç”¨æ¨¡æ“¬æ•¸æ“š
        print("\n" + "="*60)
        print("åˆ†é¡žçµæžœ (æ¨¡æ“¬)")
        print("="*60)
        
        mock_results = [
            {"sentiment": "æ­£é¢", "topic": "ç¾Žé£Ÿ", "confidence": 0.95},
            {"sentiment": "æ­£é¢", "topic": "ç§‘æŠ€", "confidence": 0.92},
            {"sentiment": "è² é¢", "topic": "å…¶ä»–", "confidence": 0.88},
            {"sentiment": "æ­£é¢", "topic": "é‹å‹•", "confidence": 0.90}
        ]
        
        for i, (text, result) in enumerate(zip(test_texts, mock_results), 1):
            print(f"\næ–‡æœ¬ {i}: {text}")
            print(f"  æƒ…æ„Ÿ: {result['sentiment']}")
            print(f"  ä¸»é¡Œ: {result['topic']}")
            print(f"  ä¿¡å¿ƒåº¦: {result['confidence']:.2f}")
    else:
        # å¯¦éš›èª¿ç”¨ API
        print("\n" + "="*60)
        print("åˆ†é¡žçµæžœ")
        print("="*60)
        
        results = []
        for i, text in enumerate(test_texts, 1):
            print(f"\næ­£åœ¨åˆ†é¡žç¬¬ {i} å€‹æ–‡æœ¬...")
            result = ai_classify(text, api_key)
            results.append(result)
            
            print(f"æ–‡æœ¬ {i}: {text}")
            print(f"  æƒ…æ„Ÿ: {result.get('sentiment', 'æœªçŸ¥')}")
            print(f"  ä¸»é¡Œ: {result.get('topic', 'å…¶ä»–')}")
            print(f"  ä¿¡å¿ƒåº¦: {result.get('confidence', 0.0):.2f}")
            if 'error' in result:
                print(f"  éŒ¯èª¤: {result['error']}")
        
        # å„²å­˜çµæžœ
        os.makedirs('results', exist_ok=True)
        with open('results/b2_classification_results.json', 'w', encoding='utf-8') as f:
            json.dump({
                'test_texts': test_texts,
                'results': results
            }, f, ensure_ascii=False, indent=2)
        
        print("\nâœ“ çµæžœå·²å„²å­˜è‡³: results/b2_classification_results.json")
    
    print("\n" + "="*60)
    print("âœ“ B-2 å®Œæˆï¼")
    print("="*60)


# ============================================================
# B-3: AI è‡ªå‹•æ‘˜è¦ (10 åˆ†)
# ============================================================
def run_b3():
    """B-3: AI è‡ªå‹•æ‘˜è¦"""
    print("\n\nB-3: AI è‡ªå‹•æ‘˜è¦ (10 åˆ†)")
    print("="*60)
    print("ä½¿ç”¨ gpt-4o ç”Ÿæˆæ‘˜è¦\n")
    
    def ai_summarize(text, max_length, api_key):
        """
        ä½¿ç”¨ gpt-4o ç”Ÿæˆæ‘˜è¦
        
        è¦æ±‚:
        1. å¯æŽ§åˆ¶æ‘˜è¦é•·åº¦
        2. ä¿ç•™é—œéµè³‡è¨Š
        3. èªžå¥é€šé †
        """
        try:
            client = OpenAI(api_key=api_key)
            
            prompt = f"""
è«‹ç‚ºä»¥ä¸‹æ–‡ç« ç”Ÿæˆæ‘˜è¦ã€‚

è¦æ±‚:
1. æ‘˜è¦é•·åº¦ä¸è¶…éŽ {max_length} å­—
2. ä¿ç•™æ–‡ç« çš„é—œéµè³‡è¨Šå’Œä¸»è¦è«–é»ž
3. èªžå¥é€šé †ï¼Œé‚è¼¯æ¸…æ™°
4. ä¸è¦æ·»åŠ åŽŸæ–‡æ²’æœ‰çš„å…§å®¹

æ–‡ç« :
{text}

è«‹ç›´æŽ¥è¼¸å‡ºæ‘˜è¦å…§å®¹ï¼Œä¸è¦å…¶ä»–èªªæ˜Žã€‚
"""
            
            response = client.chat.completions.create(
                model="gpt-4o",
                messages=[
                    {"role": "system", "content": "ä½ æ˜¯ä¸€å€‹å°ˆæ¥­çš„æ–‡ç« æ‘˜è¦åŠ©æ‰‹ï¼Œæ“…é•·æå–é—œéµè³‡è¨Šä¸¦ç”Ÿæˆç°¡æ½”æ‘˜è¦ã€‚"},
                    {"role": "user", "content": prompt}
                ],
                temperature=0.5,
                max_tokens=max_length * 2  # è€ƒæ…® token èˆ‡å­—æ•¸çš„é—œä¿‚
            )
            
            summary = response.choices[0].message.content.strip()
            
            return {
                'summary': summary,
                'length': len(summary),
                'compression_ratio': (1 - len(summary) / len(text)) * 100
            }
            
        except Exception as e:
            print(f"âš  API éŒ¯èª¤: {e}")
            return {
                'summary': '',
                'length': 0,
                'compression_ratio': 0,
                'error': str(e)
            }
    
    # æ¸¬è©¦æ–‡ç« 
    article = """
äººå·¥æ™ºæ…§ï¼ˆAIï¼‰çš„ç™¼å±•æ­£åœ¨æ·±åˆ»æ”¹è®Šæˆ‘å€‘çš„ç”Ÿæ´»æ–¹å¼ã€‚å¾žæ—©ä¸Šèµ·åºŠæ™‚çš„æ™ºæ…§é¬§é˜ï¼Œåˆ°é€šå‹¤æ™‚çš„è·¯ç·šè¦åŠƒï¼Œå†åˆ°å·¥ä½œä¸­çš„å„ç¨®è¼”åŠ©å·¥å…·ï¼ŒAIç„¡è™•ä¸åœ¨ã€‚

åœ¨é†«ç™‚é ˜åŸŸï¼ŒAIå”åŠ©é†«ç”Ÿé€²è¡Œç–¾ç—…è¨ºæ–·ï¼Œæé«˜äº†è¨ºæ–·çš„æº–ç¢ºçŽ‡å’Œæ•ˆçŽ‡ã€‚é€éŽåˆ†æžå¤§é‡çš„é†«ç™‚å½±åƒå’Œç—…æ­·è³‡æ–™ï¼ŒAIèƒ½å¤ ç™¼ç¾äººçœ¼å®¹æ˜“å¿½ç•¥çš„ç´°ç¯€ï¼Œç‚ºæ‚£è€…æä¾›æ›´å¥½çš„æ²»ç™‚æ–¹æ¡ˆã€‚

æ•™è‚²æ–¹é¢ï¼ŒAIå€‹äººåŒ–å­¸ç¿’ç³»çµ±èƒ½å¤ æ ¹æ“šæ¯å€‹å­¸ç”Ÿçš„å­¸ç¿’é€²åº¦å’Œç‰¹é»žï¼Œæä¾›å®¢è£½åŒ–çš„æ•™å­¸å…§å®¹ã€‚é€™ç¨®å› ææ–½æ•™çš„æ–¹å¼ï¼Œè®“å­¸ç¿’è®Šå¾—æ›´åŠ é«˜æ•ˆå’Œæœ‰è¶£ã€‚

ç„¶è€Œï¼ŒAIçš„å¿«é€Ÿç™¼å±•ä¹Ÿå¸¶ä¾†äº†ä¸€äº›æŒ‘æˆ°ã€‚é¦–å…ˆæ˜¯å°±æ¥­å•é¡Œï¼Œè¨±å¤šå‚³çµ±å·¥ä½œå¯èƒ½æœƒè¢«AIå–ä»£ã€‚å…¶æ¬¡æ˜¯éš±ç§å’Œå®‰å…¨å•é¡Œï¼ŒAIç³»çµ±éœ€è¦å¤§é‡æ•¸æ“šä¾†è¨“ç·´ï¼Œå¦‚ä½•ä¿è­·å€‹äººéš±ç§æˆç‚ºé‡è¦è­°é¡Œã€‚æœ€å¾Œæ˜¯å€«ç†å•é¡Œï¼ŒAIçš„æ±ºç­–éŽç¨‹å¾€å¾€ç¼ºä¹é€æ˜Žåº¦ï¼Œå¯èƒ½æœƒç”¢ç”Ÿåè¦‹æˆ–æ­§è¦–ã€‚

é¢å°é€™äº›æŒ‘æˆ°ï¼Œæˆ‘å€‘éœ€è¦åœ¨æŽ¨å‹•AIç™¼å±•çš„åŒæ™‚ï¼Œå»ºç«‹ç›¸æ‡‰çš„æ³•å¾‹æ³•è¦å’Œå€«ç†æº–å‰‡ã€‚åªæœ‰é€™æ¨£ï¼Œæ‰èƒ½ç¢ºä¿AIæŠ€è¡“çœŸæ­£ç‚ºäººé¡žç¦ç¥‰æœå‹™ï¼Œå‰µé€ ä¸€å€‹æ›´ç¾Žå¥½çš„æœªä¾†ã€‚
"""
    
    print("æ¸¬è©¦æ–‡ç« :")
    print("="*60)
    print(article.strip())
    print("="*60)
    print(f"\nåŽŸæ–‡å­—æ•¸: {len(article)} å­—")
    
    # æª¢æŸ¥ API Key
    api_key = os.getenv('OPENAI_API_KEY')
    if not api_key:
        print("\n" + "="*60)
        print("âš  è­¦å‘Š: æœªè¨­ç½® OPENAI_API_KEY ç’°å¢ƒè®Šæ•¸")
        print("="*60)
        print("\nä½¿ç”¨æ¨¡æ“¬æ•¸æ“šé€²è¡Œæ¼”ç¤º...")
        
        # ä½¿ç”¨æ¨¡æ“¬æ•¸æ“š
        print("\n" + "="*60)
        print("æ‘˜è¦çµæžœ (æ¨¡æ“¬)")
        print("="*60)
        
        mock_summary_100 = "äººå·¥æ™ºæ…§æ­£åœ¨æ”¹è®Šæˆ‘å€‘çš„ç”Ÿæ´»ï¼Œåœ¨é†«ç™‚å’Œæ•™è‚²é ˜åŸŸå¸¶ä¾†é©æ–°ã€‚ç„¶è€Œä¹Ÿé¢è‡¨å°±æ¥­ã€éš±ç§å’Œå€«ç†ç­‰æŒ‘æˆ°ï¼Œéœ€è¦å»ºç«‹ç›¸æ‡‰çš„æ³•è¦å’Œæº–å‰‡ã€‚"
        mock_summary_150 = "äººå·¥æ™ºæ…§ï¼ˆAIï¼‰æ·±åˆ»æ”¹è®Šæˆ‘å€‘çš„ç”Ÿæ´»æ–¹å¼ï¼Œåœ¨é†«ç™‚é ˜åŸŸå”åŠ©è¨ºæ–·ã€æé«˜æº–ç¢ºçŽ‡ï¼Œåœ¨æ•™è‚²æ–¹é¢æä¾›å€‹äººåŒ–å­¸ç¿’ã€‚ä½†AIç™¼å±•ä¹Ÿå¸¶ä¾†å°±æ¥­ã€éš±ç§å’Œå€«ç†æŒ‘æˆ°ï¼Œéœ€è¦åœ¨æŽ¨å‹•ç™¼å±•çš„åŒæ™‚å»ºç«‹ç›¸æ‡‰çš„æ³•å¾‹æ³•è¦å’Œå€«ç†æº–å‰‡ï¼Œç¢ºä¿AIç‚ºäººé¡žç¦ç¥‰æœå‹™ã€‚"
        
        for max_len, summary in [(100, mock_summary_100), (150, mock_summary_150)]:
            print(f"\næ‘˜è¦é•·åº¦é™åˆ¶: {max_len} å­—")
            print("-"*60)
            print(f"æ‘˜è¦: {summary}")
            print(f"å¯¦éš›é•·åº¦: {len(summary)} å­—")
            print(f"å£“ç¸®çŽ‡: {(1 - len(summary) / len(article)) * 100:.1f}%")
    else:
        # å¯¦éš›èª¿ç”¨ API
        print("\n" + "="*60)
        print("æ‘˜è¦çµæžœ")
        print("="*60)
        
        results = {}
        for max_length in [100, 150]:
            print(f"\næ­£åœ¨ç”Ÿæˆ {max_length} å­—æ‘˜è¦...")
            result = ai_summarize(article, max_length, api_key)
            results[max_length] = result
            
            print(f"\næ‘˜è¦é•·åº¦é™åˆ¶: {max_length} å­—")
            print("-"*60)
            if 'error' in result:
                print(f"éŒ¯èª¤: {result['error']}")
            else:
                print(f"æ‘˜è¦: {result['summary']}")
                print(f"å¯¦éš›é•·åº¦: {result['length']} å­—")
                print(f"å£“ç¸®çŽ‡: {result['compression_ratio']:.1f}%")
        
        # å„²å­˜çµæžœ
        os.makedirs('results', exist_ok=True)
        with open('results/b3_summary_results.json', 'w', encoding='utf-8') as f:
            json.dump({
                'article': article,
                'article_length': len(article),
                'results': results
            }, f, ensure_ascii=False, indent=2)
        
        print("\nâœ“ çµæžœå·²å„²å­˜è‡³: results/b3_summary_results.json")
    
    print("\n" + "="*60)
    print("âœ“ B-3 å®Œæˆï¼")
    print("="*60)


# ============================================================
# ä¸»ç¨‹å¼
# ============================================================
def main(task=None):
    """
    ä¸»ç¨‹å¼å…¥å£
    task: 'B1', 'B2', 'B3', 'ALL', None
    """
    print("Part B: ç¾ä»£ AI æ–¹æ³• (ä½¿ç”¨ OpenAI gpt-4o)")
    print("="*60)
    
    # æª¢æŸ¥ OpenAI å¥—ä»¶
    try:
        import openai
        print(f"âœ“ OpenAI å¥—ä»¶ç‰ˆæœ¬: {openai.__version__}")
    except ImportError:
        print("âš  è­¦å‘Š: æœªå®‰è£ openai å¥—ä»¶")
        print("è«‹åŸ·è¡Œ: pip install openai")
        return
    
    if task == 'B1':
        run_b1()
    elif task == 'B2':
        run_b2()
    elif task == 'B3':
        run_b3()
    elif task == 'ALL' or task is None:
        run_b1()
        run_b2()
        run_b3()
    else:
        print(f"âš  ç„¡æ•ˆçš„ä»»å‹™: {task}")
        return
    
    print("\n" + "="*60)
    print("ðŸŽ‰ Part B å®Œæˆï¼")
    print("="*60)
    print("\nçµæžœæª”æ¡ˆä½æ–¼ results/ è³‡æ–™å¤¾")


if __name__ == "__main__":
    # æ”¯æ´å‘½ä»¤åˆ—åƒæ•¸
    if len(sys.argv) > 1:
        task = sys.argv[1].upper()
        main(task)
    else:
        main('ALL')